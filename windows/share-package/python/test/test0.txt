基于GEP神经网络的函数发现方法

 

摘要：本文先介绍了GEP神经网络的基本方法，然后指出了这种方法在函数发现中所存在的问题，并对其进行了改进，提出了一种改进的混合式GEP神经网络方法，再通过实验说明了该新方法在函数发现问题中的效果。

 

0 引言

	函数发现是GEP目前主要能解决的四大问题之一。GEP不仅能处理简单的函数发现问题，而且在复杂函数发现问题上也能取得比较好的效果。由GEP表达式树与神经网络结构上的相似，就会考虑能否将两者结合起来，看能否达到一个更好的效果。实际中发现，基本的GEP神经网络结构在处理二维及以上函数发现问题上是行不通的。针对这种情况，本文提出了一种改进的混合式GEP神经网络结构，比较好地解决了这个问题。

1 GEP神经网络的基本方法

1.1 GEP简介

2001 年12 月，葡萄牙的Candida Ferreira 在遗传算法和遗传编程的基础上提出了基因表达式编程（Gene Expression Programming，GEP）的概念，GEP 同传统的遗传算法和遗传编程（Genetic Programming，GP）在一些主要步骤上很相似，但在个体的编码方法及结果的表现形式等方面又有明显的区别。作为一种新的进化技术,GEP同样是使用一种遗传算法通过选择、交叉、变异运算来反复地来进化个体种群，从而来找到最优解。和GP相同的是，在使用GEP解决问题的时候，五个部分（函数集、终结符、适应度函数、控制参数和终止条件）必须确定。与一种规范的GP中的解析树表示法不同的是，GEP使用一种固定长度的字符串来表示计算机程序，随后在计算适应度时采用了不同大小和形状的解析树（在GEP中称为表达式树）来表示。在繁殖中，是个体的染色带体而不是表达式树(ETs)通过修改和传播被复制到下一代。和GA相同的是，GEP中的染色体是线性的、简洁的，而且容易进行遗传操作；和GP相同的是，表达式树形式的进化的计算机程序，展现了一种特定数量的函数复杂度。而且这种染色体和表达式树的内部转化是相当简单的。由于这些特性，GEP结合了GA和GP两者的优点，这为解决复杂的建模和优化问题提供了巨大的潜力[5]。

1.2 人工神经网络介绍

人工神经网络是由大量的处理单元（神经元）广泛互连而成的网络，这些单元或者节点之间的联系通常采用实数型的权值来表示。权值是神经网络学习的主要方法，学习算法经常被用来调节这些权值。人工神经网络是对有脑的抽象、简化和模拟，反映人脑的基本特性，它的研究是从人脑的生理结构出发来研究人的智能行为，模拟人脑信息处理的功能。它是根植于神经科学、数学、统计学、物理学、计算机科学及工程等学科的一种技术。

神经网络是由简单的处理单元所组成的大量并行分布的处理机，这种处理机具有存储和应用经验知识的自然特性，它与有脑的相似之处概括为两个方面：一是通过学习过程利用神经网络从外部环境中获取知识；二是内部神经元（突触权值）用来存储获取的知识信息。

从结构上说，一个神经网络具有3种不同类型的单元：输入、隐藏和输出单元。输入单元上提供一种激活模式，该模式以向前传播的方式从输入单元经一层或多层的隐藏单元到达输出单元。这个激活模式在从一个单元进入其它单元时需要与其传播方向上的连接权值相乘。然后，所有的输入激活值相加，只有当输入结果大于该单元的阈值时这个单元才被激活。 

神经网络是近年来的热点研究领域，涉及到多个学科的交叉，其应用领域包括：建模、时间序列分析、模式识别和控制等，并在此不断的拓展。相信随着人工神经网络研究的进一步深入，特别是人工神经网络作为一种智能方法同其他学科领域更为紧密的结合，人工神经网络的应用前景将更为广阔。

1.3 GEP神经网络介绍

GEP神经网络是GEP与人工神经网络的结合，它是利用GEP中个体的进化来代替人工神经网络中的学习过程。由于GEP中表达式树的表示方式与神经网络中的结构非常相似，我们只要在连接基因中的各个单元之间增加一个权值，在基因中的每个非终结符中增加一个阈值，那么该表达式树的结构就非常接近于神经网络结构了。为了使表达式树具体这种结构，我们必须修改GEP的染色体以使其能够将一个完整的神经网络，包括其结构、权值和阈值，完全编码在一个线性染色体中。

在GEP神经网络中，网络结构编码在一个类似于头/尾域的结构中。头部含有能够激活隐藏和输出单元的特殊函数（在GEP的语境下，称之为功能单元更恰当）和用来表示输入单元的终点，尾部显然只含有终点。除了头部和尾部以外，这些基因还含有两个附加域， 和 ，分别用来对权值和阈值进行编码。从结构上来说， 出现在尾部之后，其长度 。 出现在 域之后，其长度 ＝h（其中h代表头部长度，n代表最大目数）。这两个域都由神经网络中代表权值和阈值的符号构成。在实现上，我们可以先分别产生一个权值和阈值集合的数值，然后我们就可以用权值和阈值数组中的索引号集合来构成 和 这两个附加域。

考虑下面这个传统方法表示的神经网络，它由两个输入单元（ 和 ），两个隐藏单元（ 和 ）和一个输出单元（ ）构成（为了简单，阈值均等于1，并省略）：

 



它还可以用一个传统的树形结构来表示：

  

其中a，b分别表示两个输入i1和i2，“D”表示具有两个连通分量的函数。该函数用参数乘以相应的权值，并对所有的输入激活值求和以得到向前输出。这个输出（0或1）依赖于阈值，即如果输入激活值之和等于或者大于这个阈值，则输出为1，否则为0。 

我们可以将上面的这个神经网络-树线性化成如下形式： 

0123456789012 

DDDabab123456

其中粗体结构对权值进行编码。每个权值的值保存在一个数组中并可以随时取出。为了简化问题， 中的数字代表数组中的顺序。该编码方式在解码构成树结构时，相应的 值从染色体中自后向前读取，按照从下到上，从右到左的顺序出现在树的分支上。

2 GEP神经网络基本方法的缺陷

GEP神经网络已经能够很好地解决神经网络网络领域中的重要问题，即异或问题。另外GEP神经网络还能还能用来解决相当复杂的问题，即6-位多路由器问题[4]。我们知道，GEP是能够用于函数挖掘领域的，这样自然就会考虑，GEP神经网络能否同样用于函数挖掘呢？通过分析GEP神经网络的表达式树结构发现，这种GEP神经网络只能进行解决一维的函数发现问题，因为按照现有GEP神经网络的结构，它不可能产生一个高于一次的函数。例如对于产生如下一个单基因染色体：

0123456789012345678901234 567890123456789012345678901234

UDFDaDaaaaaaaaaaaaaaaaaaa 776002057802830092572074421510

它所对应的表达式树结构如下图所示：(其中U，Ｄ，Ｈ，Ｆ分别表示有一个、二个、三个和四个连通分量的函数，数字代表它所对应的权值或阈值数组中的索引号，为简单起见，我们没有将阈值标出来)

 

从表达式树中我们可以看出，对于非终结符而言，它的输出值是对应每个子结点的值与对应的权值的累加和与阈值的差，对终结符而言，它的输出值就是它本身所代表的数据集中的值。所以不管染色体怎么进化，它都只是停留在一次函数阶段，即只可能出现 的形式，所以当用这样一种GEP神经网络来挖掘二次或更高次函数时，误差明显会比较大，因为不管怎样，所找到的函数形式永远只是一条接近或者说逼近于该二次或高次函数。因此，这种形式的GEP神经网络几乎在函数发现领域不可行，我们必须对它进行改进才能应用于二次或以上函数的发现问题。

3 GEP神经网络的改进

为了对上面提到的致命缺陷进行改进，我们在原有GEP神经网络的基础之上提出了一种混合式的GEP神经网络结构。即我们增加了一些原GEP当中的函数集混合到现有的GEP神经网络函数集中，这些增加的函数所代表的意义就是它本身的意义，如函数’＊’，就是表示它的两个子结点相乘，而且，我们在表达式树中，不对它们分配权值和阈值，因此，在这种结构的表达式树中，有部分子树就是原ＧＥＰ表达式树的结构，而部分子树却是现有的GEP神经网络表达式树的结构，这两种类型的子树结合在一起，就构成了混合式的ＧＥＰ神经网络结构。

例如，对于如下这个h=8的染色体的基因型

D*H*U*U/aaaaaaaaaaaaaaaaaaaaaaaaa41532553127661349794074113560094

26232133

它的表达式树如下：

  

 

对于权值数组weights={-1.553,1.612,-1.606,-0.487,1.475,-0.253,-1.91,

1.427,-0.103,-1.375}及阈值数组thresholds={-1.14,1.125,-1.173,-0.74,

0.393,1.135,-0.625,1.523,-0.029,-1.634}，上面的表达式树变成：

 

 

 

在不使用权值、阈值的情况下，上述表达式树结构实际上就是对于 函数发现问题的一个完美解。

我们知道，GEP是能够解决复杂高次的函数发现问题的，所以通过学习这种混合结构，我们就巧妙地将GEP的这个特性加入到了GEP神经网络中，从而达到弥补GEP神经网络不能发现二次及以上函数发现问题的缺陷。

在实际的函数发现问题中,我们有两种类型的权值、阈值分别用来解决不同类型的函数发现问题。一种是不使用权、阈值，即把所有的权值设为1，所有的阈值设为0，通过这种方式的权阈值来发现具有整数系数的函数；另一种是使用浮点数权、阈值，在实际中,我们是事先设定一个拥有特定个元素个数的权、阈值数组，然后在编码成树结构中的所有权、阈值都是从这两个特定的数组中选取的。

为了构造我们需要的GEP神经网络结构，我们采用了一种多域结构的染色体，即在原来的基因尾部添加了权值域和阈值域。为此，我们在原有的WEKA平台上进行了修改和扩展，让它产生满足这种特定需要的多域基因，并重写了对这种特定基因的解码方式，另外还增加和修改了针对这种特定基因的遗传操作算子，以满足我们特定的需求。为了简化问题和更贴切地模拟神经网络，我们仅仅使用的是单基因结构的染色体。在实际的实现中，我们采用了两个长度均为10的数组来作为权值和阈值所有取值的组合，因为在大部分情况下，使用长度为10 的数组就能够取得很好的效果[4]。这样，这种多域结构染色体中的权值域和阈值域实际上就可以分别用它们所对应的权值和阈值数组中的索引组合来构成。

 

4 GEP神经网络改进的效果

4.1 实验1

在这个实验中，我们是测试简单多项式函数 的函数发现问题。对数据集重复10次挖掘实验,最后取统计结果的平均值作为最后的实验结果。实验中GEP各参数设置如表1所示。

 

表1　实验1中的GEP参数



运行次数	10	染色体长度	73

最大进化代数	5000	变异概率	0.044

种群大小	20	基因内两点重组概率	0.6

函数集	UDHF*/	IS转座概率	0.1

终结符集	a	IS元素长度	1,2,3

连接函数	无	RIS转座概率	0.1

基因个数	1	RIS元素长度	1,2,3

头部长度	8	附加域转座概率	0.1

函数最大目数	4		



 

在实验中，我们采用的是绝对误差适应度函数： ，其中M是选择范围， 是染色体个体i对于适应度样本（来自集合中）的返回值。而是适应度样本的目标值。因此，对于一个完美适应的情况， = 且 =f max = M。当我们取M=100时，对于该测试集的完美解时 =2500，运行结果如下表所示：

 



运行

次数	１	２	３	４	５	６	７	８	９	１０

最大适应度	2499.190	2498.303	2498.752	2496.808	2499.035	2494.774	2498.658	2497.833	2499.3815	2498.054

 

从以上实验室结果中我们可以看出，我们构造的GEP神经网络结构对函数表达式进行了一个比较好的模拟，也正是因为我们只是用这样一种神经网络表达式树结构对函数进行一种逼近，所以，理论上几乎不可能找出完美解。

4.2 实验２

对于浮点系数函数 ，我们仍采用上述实验室中的基本参数设定。对于只有10个数据的测试集，对于完美解时  =1000，运行结果如下表所示：

 

运行

次数	１	２	３	４	５	６	７	８	９	１０

训练最大适应度	994.203	993.099	985.993	984.428	995.890	996.095	991.910	997.430	994.883	987.095

5-叠

交叉

测试	1	789.394	799.103	798.299	797.640	797.465	789.393	797.195	786.187	797.575	796.917

	2	785.243	798.325	785.396	784.860	794.269	793.4410	781.114	785.243	785.414	799.685

	3	790.164	782.953	794.144	794.798	798.782	774.727	777.813	782.944	774.187	782.965

	4	786.700	798.230	796.084	795.468	799.408	799.4641	782.629	799.367	786.722	795.892

	5	796.762	797.659	799.458	793.270	798.707	796.768	796.975	792.823	795.587	799.481

 

从以上测试数据我们可以看出，我们利用这种混合GEP神经网络对这种浮点系数的函数也同样达到了一个比较好的挖掘效果。如果直接利用GEP进行函数发现，对此我们也同样做了大量的实验，其结果正如当初我们所预想的一样，最多只能发现  , , 或 这几种最为接近的函数表达式。当然，利用Candida Ferreira所提出的数值常数的产生引入到符号回归问题中[3]，还是同样能达到一个比较好的效果的。 

4.3 实验3

 

前面我们提到过，在实际的函数发现问题中,我们有两种类型的权值、阈值分别用来解决不同类型的函数发现问题。前面对使用浮点数权、阈值已经实验室过了，现在来看另一种，即不使用权、阈值，也就是把所有的权值设为1，所有的阈值设为0。下面通过实验来看这种方式的权、阈值设置来发现具有整数系数的函数的效果。在这个实验

 

运行

次数	１	２	３	４	５

训练最大适应度	999.998	999.998	999.998	999.9984	999.998



5-叠

交叉

测试	1	799.998	799.998	799.998	799.998	799.998

	2	799.999	799.999	799.999	799.999	799.999

	3	799.999	799.999	799.999	792.000	799.999

	4	799.999	799.999	799.999	799.999	799.999

	5	799.999	799.999	799.999	799.999	799.999

 

从以上实验数据可以看出，不论是训练还是测试的最大适应度，都非常非常接近完美值，我们分析以上适应度所对应的染色体可以发现，其实已经完全准确无误地找到了目标函数（除了其中的第４次运行中5-叠交叉中的第３组数据792.000），只是所发现的染色体的表现型不一样而已，由于运算过程中存在误差，所以才只是非常地接近完美值。

	大胆设想一下，如果我们不用GEP神经网络特有的函数集，而只用原GEP中的函数集，并且不使用权、阈值，将会得出怎样一种结构呢？不难想出，其实这就是一般的GEP表达式树结构。所以从这个层面来说，我们这种混合式的GEP神经网络结构是对原GEP结构的一种拓展，换个方式说，原GEP结构只是我们这种混合GEP神经网络的一种特例。

5 结论

在本文中，我们提出了一种混合式的GEP神经网络结构，并且仍用一种固定长度的多域线性染色体来表达，并用这种特殊的结构来做函数发现问题，包括常系数函数和浮点数系数函数。通过实验室可以看出，效果还是比较满意的。但是这种方法并不是完美的，还是存在一些问题有待改进的，比如搜索空间过大，有时会陷入局部最优等，这些都是以后有待解决的问题。今后的主要工作首先还要继续解决如何更快，更精确地完成挖掘工作，然后是解决利用这种混合式的GEP神经网络结构进行分类问题。







参考文献：

[1] Candida Ferreira. Gene Expression Programming: A New Adaptive Algorithm for Solving Problems. Complex Systems, 2001

[2] Candida Ferreira. Gene Programming in Problem Solving, 2001

[3] Candida Ferreira. Designing Neural Networks Using Gene Expression Programming, 2004

[4] Candida Ferreira. Gene Expression Programming: Mathematical Modeling by an Artificial Intelligence, 2nd Edition. Springer, 2006

[5] Chi Zhou. Gene Expression Programming And Rule Induction For Domain Knowledge Discovery And Management, 2003

[6] 周明，孙树栋。遗传算法原理及应用。北京：国防工业出版社，1999

[7] 高隽。人工神经网络原理及仿真实例。北京：机械工业出版社，2003

[8] 蒋宗礼。人工神经网络导论。北京：高等教育出版社，2001

